{"tagline":"A REST API for Mozilla Metrics services.","note":"Don't delete this file! It's used internally to help with page regeneration.","name":"Bagheera","body":"# Bagheera #\r\n\r\nVersion: 0.7-SNAPSHOT  \r\n\r\n#### REST service for Mozilla Metrics. This service currently uses Apache Kafka as its backing data store, then provides a few implementations of Kafka consumers to pull and persist to various data sinks. ####\r\n\r\n\r\n### Version Compatability ###\r\nThis code is built with the following assumptions.  You may get mixed results if you deviate from these versions.\r\n\r\n* [Kafka](http://incubator.apache.org/kafka) 0.7.1+\r\n* [Protocol Buffers](https://developers.google.com/protocol-buffers) 2.3.0+\r\n* [Hadoop](http://hadoop.apache.org) 0.20.2+\r\n* [HBase](http://hbase.apache.org) 0.90+\r\n\r\n### Prerequisites ###\r\n* Protocol Buffers\r\n* Zookeeper (for Kafka)\r\n* Kafka\r\n* Hadoop (if using HDFS based consumer)\r\n* HBase (if using HBase based consumer)\r\n\r\n### Building ###\r\nTo make a jar you can do:  \r\n\r\n`mvn package`\r\n\r\nThe jar file is then located under `target`.\r\n\r\n### Running an instance ###\r\n**Make sure your Kafka and Zookeeper servers are running first (see Kafka documentation)**\r\n\r\nIn order to run bagheera on another machine you will probably want to use the _dist_ assembly like so:\r\n\r\n`mvn assembly:assembly`\r\n\r\nThe zip file now under the `target` directory should be deployed to `BAGHEERA_HOME` on the remote server.\r\n\r\nTo run Bagheera you can use `bin/bagheera` or copy the init.d script by the same name from `bin/init.d` to `/etc/init.d`. The init script assumes an installation of bagheera at `/usr/lib/bagheera`, but this can be modified by changing the `BAGHEERA_HOME` variable near the top of that script. Here is an example of using the regular bagheera script:\r\n\r\n`bin/bagheera 8080`\r\n\r\n### REST Request Format ###\r\n#####URI _/submit/namespace/id_#####\r\nPOST/PUT \r\n* The _namespace_ is required and is only accepted if it is in the configured white-list.\r\n* The _id_ is optional although if you provide it currently it needs to be a valid UUID unless id validation is disabled on the _namespace_. \r\n* The payload content length must be less than the configured maximum.\r\n\r\nDELETE\r\n* The _namespace_ is required and is only accepted if it is in the configured white-list.\r\n* The _id_ is required although if you provide it currently it needs to be a valid UUID unless id validation is disabled on the _namespace_.\r\n\r\nHere's the list of HTTP response codes that Bagheera could send back:\r\n\r\n* 201 Created - Returns the id submitted/generated. (default)\r\n* 403 Forbidden - Violated access restrictions. Most likely because of the method used.\r\n* 413 Request Too Large - Request payload was larger than the configured maximum.\r\n* 400 Bad Request - Returned if the POST/PUT failed validation in some manner.\r\n* 404 Not Found - Returned if the URI path doesn't exist or if the URI was not in the proper format.\r\n* 500 Server Error - General server error. Someone with access should look at the logs for more details.\r\n\r\n### Example Bagheera Configuration (conf/bagheera.properties) ###\r\n    # valid namespaces (whitelist only, comma separated)\r\n    valid.namespaces=mynamespace,othernamespace\r\n    max.content.length=1048576\r\n\r\n### Example Kafka Producer Configuration (conf/kafka.producer.properties) ###\r\n    # comma delimited list of ZK servers\r\n    zk.connect=127.0.0.1:2181\r\n    # use bagheera message encoder\r\n    serializer.class=com.mozilla.bagheera.serializer.BagheeraEncoder\r\n    # asynchronous producer\r\n    producer.type=async\r\n    # compression.code (0=uncompressed,1=gzip,2=snappy)\r\n    compression.codec=2\r\n    # batch size (one of many knobs to turn in kafka depending on expected data size and request rate)\r\n    batch.size=100\r\n\r\n### Example Kafka Consumer Configuration (conf/kafka.consumer.properties) ###\r\n    # kafka consumer properties\r\n    zk.connect=127.0.0.1:2181\r\n    fetch.size=1048576\r\n    #serializer.class=com.mozilla.bagheera.serializer.BagheeraDecoder\r\n    # bagheera specific kafka consumer properties\r\n    consumer.threads=2\r\n\r\n### Notes on consumers ###\r\nWe currently use the consumers implemented here, but it may also be of interest to look at systems such as [Storm](https://github.com/nathanmarz/storm) to process the messages. Storm contains a Kafka spout (consumer) and there are at least a couple of HBase bolts (processing/sink) already out there.\r\n\r\n### License ###\r\nAll aspects of this software are distributed under Apache Software License 2.0. See LICENSE file for full license text.\r\n\r\n### Contributors ###\r\n\r\n* Xavier Stevens ([@xstevens](http://twitter.com/xstevens))\r\n* Daniel Einspanjer ([@deinspanjer](http://twitter.com/deinspanjer))\r\n* Anurag Phadke ([@anuragphadke](http://twitter.com/anuragphadke))\r\n* Mark Reid ([@reid_write](http://twitter.com/reid_write))\r\n","google":""}